
# ğŸŒ‘ğŸ§ **Spotify Real-Time Data Analysis Pipeline **


### ğŸš€ **Real-Time â†’ Batch Modern Data Stack**
**Kafka â†’ MinIO â†’ Airflow â†’ Snowflake â†’ dbt â†’ Analytics**

</div>

---

# ğŸ›¡ï¸ **Tech Stack**

<div align="center">

<img src="https://img.shields.io/badge/Python-3.10-3776AB?logo=python&logoColor=white&style=for-the-badge">  
<img src="https://img.shields.io/badge/Kafka-Streaming-231F20?logo=apachekafka&logoColor=white&style=for-the-badge">  
<img src="https://img.shields.io/badge/MinIO-Object%20Storage-C72A2C?logo=minio&logoColor=white&style=for-the-badge">  
<img src="https://img.shields.io/badge/Airflow-Orchestration-017CEE?logo=apacheairflow&logoColor=white&style=for-the-badge">  
<img src="https://img.shields.io/badge/Snowflake-Data%20Warehouse-29B5E8?logo=snowflake&logoColor=white&style=for-the-badge">  
<img src="https://img.shields.io/badge/dbt-Transformations-FD4F00?logo=dbt&logoColor=white&style=for-the-badge">  
<img src="https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white&style=for-the-badge">

</div>

---

# ğŸŒŒ **Project Summary**

This end-to-end data engineering pipeline simulates **Spotify user events** and processes them through a **real-time ingestion â†’ batch analytics workflow**.

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Streaming** | Kafka | Real-time user events |
| **Data Lake** | MinIO (S3) | Raw Bronze storage |
| **Orchestration** | Airflow | ETL to Snowflake |
| **Warehouse** | Snowflake | Bronze â†’ Staging â†’ Silver |
| **Transformations** | dbt | Models, tests, documentation |
| **Analytics** | SQL + Dashboards | Song analytics, user engagement |

---


# ğŸ—‚ **Folder Structure**

```
project/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ spotify_minio_to_snowflake_bronze.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer.py
â”‚   â”œâ”€â”€ consumer.py
â”‚
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â”œâ”€â”€ models/
â”‚       â”œâ”€â”€ bronze/
â”‚       â”œâ”€â”€ staging/
â”‚       â”œâ”€â”€ silver/
â”‚       â””â”€â”€ marts/
```

---

# ğŸ”§ **Setup**

### Install dependencies:
```bash
pip install -r requirements.txt
```

### Configure `.env`:
```env
MINIO_ENDPOINT=http://minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

KAFKA_BOOTSTRAP_SERVERS=localhost:29092
KAFKA_TOPIC=spotify-events

SNOWFLAKE_USER=xxxx
SNOWFLAKE_PASSWORD=xxxx
SNOWFLAKE_ACCOUNT=xxxx
```

---

# ğŸ³ **Start Infrastructure**
Initialize Airflow DB:
```bash
docker compose up airflow-init
```

Start all containers:
```bash
docker compose up -d
```

### Access UIs:
| Service | URL |
|---------|-----|
| **Airflow** | http://localhost:8080 |
| **MinIO Console** | http://localhost:9001 |
| **Kafka Broker** | PLAINTEXT://localhost:29092 |

---

# ğŸµ **Run Kafka Producer**
```bash
python src/producer.py
```

---

# ğŸ§ **Run Kafka Consumer â†’ MinIO**
```bash
python src/consumer.py
```

Example output:
```
Uploaded 10 events â†’ MinIO: bronze/date=.../hour=...
```

---

# ğŸª„ **Airflow: MinIO â†’ Snowflake Loader**

Enable DAG in Airflow:
```
spotify_minio_to_snowflake_bronze
```

The DAG:

âœ” Loads MinIO files  
âœ” Parses events  
âœ” Inserts into Snowflake  
âœ” Moves processed files  

---

# â„ï¸ **Verify Data in Snowflake**
```sql
SELECT COUNT(*) 
FROM SPOTIFY_DB.BRONZE.SPOTIFY_EVENTS_BRONZE;
```

---

# ğŸ§  **dbt Transformations**
Test dbt connection:
```bash
dbt debug
```

Run models:
```bash
dbt run
```

Run tests:
```bash
dbt test
```

---

# ğŸ“Š **Analytics Queries**

### Top Songs
```sql
SELECT * 
FROM {{ ref('song_popularity') }}
ORDER BY total_plays DESC;
```

### User Activity
```sql
SELECT *
FROM {{ ref('user_activity_daily') }}
ORDER BY plays DESC;
```

---



---

